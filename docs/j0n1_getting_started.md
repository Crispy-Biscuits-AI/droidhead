# Getting Started with J0N1

1. Set up your Jetson / host machine.
2. Install n8n and your preferred local models (Quick/Reasoning/Code).
3. Configure volumes so `prompts/` and `system/` are accessible to n8n.
4. Import the example workflow from `workflows/n8n_j0n1_example.json`.
5. Configure any HTTP nodes to point at your local LLM endpoints.
6. Test with a simple prompt to J0N1: "J0N1, report your current status."
